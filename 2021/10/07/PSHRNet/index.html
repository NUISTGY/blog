<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="✨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification"><meta name="keywords" content="行人重识别,论文"><meta name="author" content="GeYu"><meta name="copyright" content="GeYu"><title>✨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification | Yu's Blog</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Contents-🗒"><span class="toc-number">1.</span> <span class="toc-text">Contents 🗒</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction-🗒"><span class="toc-number">2.</span> <span class="toc-text">Introduction 🗒</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Usage-🔧"><span class="toc-number">3.</span> <span class="toc-text">Usage 🔧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results-🏆"><span class="toc-number">4.</span> <span class="toc-text">Results 🏆</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Acknowledgements-👍"><span class="toc-number">5.</span> <span class="toc-text">Acknowledgements 👍</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://images5.alphacoders.com/423/423529.jpg"></div><div class="author-info__name text-center">GeYu</div><div class="author-info__description text-center">Do what you want to do !</div><div class="follow-button"><a href="https://github.com/NUISTGY">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">225</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">82</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">45</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.328888.xyz/2022/12/21/ARudF.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Yu's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span></div><div id="post-info"><div id="post-title">✨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-10-07</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/行人重识别/">行人重识别</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">390</span><span class="post-meta__separator">|</span><span>阅读时长: 2 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><script src="/assets/js/APlayer.min.js"> </script><div align="center">

<p><a href="https://ieeexplore.ieee.org/document/9591273/authors#citations" target="_blank" rel="noopener"><strong><front size="5">Journal of IEEE TIP (SCI-Q1 Top)</front></strong></a></p>
<center>
G. Zhang, 👉Y. Ge👈, Z. Dong, H. Wang, Y. Zheng and S. Chen
</center>

<p><img src="https://img.gejiba.com/images/de85252fec31e625fecf220fa7b686b8.png" alt></p>
</div>

<h2 id="Contents-🗒"><a href="#Contents-🗒" class="headerlink" title="Contents 🗒"></a><a id="contents-">Contents 🗒</a></h2><ul>
<li><a href="#contents-"><a id="contents-">Contents 🗒</a></a></li>
<li><a href="#introduction-"><a id="introduction-">Introduction 🗒</a></a></li>
<li><a href="#usage-"><a id="usage-">Usage 🔧</a></a></li>
<li><a href="#results-"><a id="result-">Results 🏆</a></a></li>
<li><a href="#acknowledgements-"><a id="acknowledgements-">Acknowledgements 👍</a></a></li>
</ul>
<h2 id="Introduction-🗒"><a href="#Introduction-🗒" class="headerlink" title="Introduction 🗒"></a><a id="introduction-">Introduction 🗒</a></h2><p>We propose a Deep High-Resolution Pseudo-Siamese Framework (PS-HRNet) to solve the cross-resolution person re-ID problem. Specifically, in order to restore the resolution of low-resolution images and make reasonable use of different channel information of feature maps, we introduce and innovate VDSR module with channel attention (CA) mechanism, named as VDSR-CA. Then we reform the HRNet by designing a novel representation head to extract discriminating features, named as HRNet-ReID. In addition, a pseudo-siamese framework is constructed to reduce the difference of feature distributions between low-resolution images and high-resolution images. The experimental results on five cross-resolution person datasets verify the effectiveness of our proposed approach. Compared with the state-of-the-art methods, our proposed PS-HRNet improves 3.4%, 6.2%, 2.5%,1.1% and 4.2% at Rank-1 on MLR-Market-1501, MLR-CUHK03, MLR-VIPeR, MLR-DukeMTMC-reID, and CAVIAR datasets, respectively.</p>
<h2 id="Usage-🔧"><a href="#Usage-🔧" class="headerlink" title="Usage 🔧"></a><a id="usage-">Usage 🔧</a></h2><p>We use apex (A PyTorch Extension) a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training. Some of the code here will be included in upstream Pytorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly as possible.Installation instructions can be found here: <a href="https://github.com/NVIDIA/apex#quick-start" target="_blank" rel="noopener">https://github.com/NVIDIA/apex#quick-start</a>.</p>
<p>We display the process of the algorithm as an ipynb file, you can use jupyter notebook to view and run it.</p>
<p>You may need HRNet-W32-C ImageNet pretrained models or learn more about HRNet: <a href="https://github.com/HRNet/HRNet-Image-Classification.git" target="_blank" rel="noopener">https://github.com/HRNet/HRNet-Image-Classification.git</a>.</p>
<p>Wanna know more detail of the first phase？ Check this：<a href="https://github.com/NUISTGY/Person-re-identification-based-on-HRNet" target="_blank" rel="noopener">https://github.com/NUISTGY/Person-re-identification-based-on-HRNet</a></p>
<h2 id="Results-🏆"><a href="#Results-🏆" class="headerlink" title="Results 🏆"></a><a id="result-">Results 🏆</a></h2><div align="center">

<p><img src="https://img.gejiba.com/images/6670ce1bd1696c28e0fedd4fbefd676f.png" alt></p>
</div>

<h2 id="Acknowledgements-👍"><a href="#Acknowledgements-👍" class="headerlink" title="Acknowledgements 👍"></a><a id="acknowledgements-">Acknowledgements 👍</a></h2><ul>
<li>This code is built on <a href="https://github.com/HRNet/HRNet-Image-Classification" target="_blank" rel="noopener">HRNet-Image-Classification</a> and <a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="noopener">Person_reID_baseline_pytorch</a>. We thank the authors for sharing their codes. To the great spirit of open source!</li>
<li>Thank <a href="https://github.com/dzc2000" target="_blank" rel="noopener">Z.Dong</a> and <a href="https://github.com/Rockdow" target="_blank" rel="noopener">H.Wang</a>, they are the most important contributors to the related work of the experiment. If you have any questions in the process of testing, you can send them by email or pose issues.</li>
<li>Thanks for the right to use the GPU workstation provided by Nanyang Technological University.</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">GeYu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://nuistgy.github.io/2021/10/07/PSHRNet/">https://nuistgy.github.io/2021/10/07/PSHRNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://nuistgy.github.io">Yu's Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/行人重识别/">行人重识别</a><a class="post-meta__tags" href="/tags/论文/">论文</a></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5befa2f76de7c6b5" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/09/06/mybatis——解决属性名和数据库字段名不一致问题（注解方式)/"><i class="fa fa-chevron-left">  </i><span>MyBatis——解决属性名和数据库字段名不一致</span></a></div><div class="next-post pull-right"><a href="/2020/07/15/论文笔记(一)/"><span>Deep Low-Resolution Person Re-Identification阅读笔记</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://i.328888.xyz/2022/12/21/ARudF.png)"><div class="layout" id="footer"><div class="copyright">&copy;2015 - 2023 By GeYu</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Enjoy the cyber world!</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>